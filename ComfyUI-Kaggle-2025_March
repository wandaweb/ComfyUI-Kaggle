{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation","metadata":{}},{"cell_type":"markdown","source":"Session options:\n * Accelerator: GPU T4 x2\n * Language: Python\n * Persistence: File Only\n * Environment: Pin to original environment\n","metadata":{}},{"cell_type":"code","source":"%%time\nupdate = False\n\nimport os\nimport stat\n!rm -rf /kaggle/working/venv\nhome_dir = '/kaggle/working'\npython = '/kaggle/working/venv/bin/python'\npip = '/kaggle/working/venv/bin/pip'\n\ndef find_bin_folders(folder_path):\n    bin_folders = []\n    for root, dirs, files in os.walk(folder_path):\n        for dir_name in dirs:\n            if dir_name == 'bin':\n                bin_folders.append(os.path.join(root, dir_name)) \n    return bin_folders\n\ndef installLibraries(home_dir, python, pip):\n  %cd {home_dir}\n  !{pip} install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n  !{pip} install tensorflow[and-cuda]\n  # TODO: download req.txt  \n  !wget https://q4j3.c11.e2-5.dev/downloads/req.txt\n  !{pip} install -r /kaggle/working/req.txt\n\n!pip install virtualenv\n\nif not os.path.exists(f'{home_dir}/venv'):\n    print('installing venv')\n    os.chdir(home_dir)\n    get_ipython().system(f'cd {home_dir}')\n    \n    get_ipython().system('virtualenv venv -p $(which python3.10)')\n    installLibraries(home_dir, python, pip)\nelse:\n    bin_folders = find_bin_folders('/kaggle/working/venv')\n    if bin_folders:\n      print(\"Found 'bin' folders:\")\n      for bin_folder in bin_folders:\n        print(bin_folder)\n        for filename in os.listdir(bin_folder):\n            file_path = os.path.join(bin_folder, filename)\n            if os.path.isfile(file_path):\n                current_permissions = os.stat(file_path).st_mode\n                 # Add execute permissions for the user, group, and others\n                os.chmod(file_path, current_permissions | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n\nif not os.path.exists(f'{home_dir}/venv/bin/python3.10'):\n    get_ipython().system('cp /opt/conda/bin/python3.10 /kaggle/working/venv/bin/')\n!ln -s /kaggle/working/venv/bin/python3.10 /kaggle/working/venv/bin/python\n!ln -s /kaggle/working/venv/bin/python3.10 /kaggle/working/venv/bin/python3\n\n%cd /kaggle/working\n!git clone https://github.com/comfyanonymous/ComfyUI.git\n%cd ComfyUI\n!git checkout 7fc3ccdcc2fb1f20c4b7dd4aca374db952fd66df\n\n#if update:\n#    get_ipython().system('git pull')\n#else:\n#    get_ipython().system('git checkout 9acfe4df41b3b0ad8c600fc2d70a3af5c82cf4a4')\n!{pip} install -r requirements.txt\n\n!mkdir /tmp/models\n!mkdir /tmp/models/checkpoints\n!mkdir /tmp/models/clip\n!mkdir /tmp/models/vae\n!mkdir /tmp/models/unet\n\n# Remove the following two lines to keep models in permanent storage\n!rm -rf /kaggle/working/ComfyUI/models/checkpoints\n!rm -rf /kaggle/working/ComfyUI/models/clip\n!rm -rf /kaggle/working/ComfyUI/models/vae\n!rm -rf /kaggle/working/ComfyUI/models/unet\n\n!ln -s /tmp/models/checkpoints /kaggle/working/ComfyUI/models/checkpoints\n!ln -s /tmp/models/clip /kaggle/working/ComfyUI/models/clip\n!ln -s /tmp/models/vae /kaggle/working/ComfyUI/models/vae\n!ln -s /tmp/models/unet /kaggle/working/ComfyUI/models/unet\n\ncheckpoints =  '/kaggle/working/ComfyUI/models/checkpoints'\nlink_path = checkpoints + '/temp-models'\ntemp_models = '/kaggle/temp/temp-models'\n\n!mkdir /kaggle/temp\n!mkdir $temp_models\n\nif not os.path.exists(link_path):\n    get_ipython().system(f'ln -s {temp_models} {checkpoints}')\n\n# Install the node manager\nupdate_manager = True\n%cd /kaggle/working/ComfyUI/custom_nodes\n!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n%cd ComfyUI-Manager\n\nif update_manager:\n    get_ipython().system('git pull')\n#!{pip} install -r requirements.txt\n\n# Pinggy script\n!wget https://raw.githubusercontent.com/wandaweb/jupyter-webui-tunneling/main/pinggy.py -O /kaggle/working/pinggy.py\n    \n# Second GPU offload\n%cd /kaggle/working/ComfyUI/custom_nodes\n!wget https://gist.githubusercontent.com/city96/30743dfdfe129b331b5676a79c3a8a39/raw/ecb4f6f5202c20ea723186c93da308212ba04cfb/ComfyBootlegOffload.py\n\n#!mamba install -y openssh\n#!{pip} install torchsde","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T11:53:40.276468Z","iopub.execute_input":"2025-03-23T11:53:40.276785Z","iopub.status.idle":"2025-03-23T11:59:07.438866Z","shell.execute_reply.started":"2025-03-23T11:53:40.276746Z","shell.execute_reply":"2025-03-23T11:59:07.437611Z"}},"outputs":[{"name":"stdout","text":"Collecting virtualenv\n  Downloading virtualenv-20.29.3-py3-none-any.whl.metadata (4.5 kB)\nCollecting distlib<1,>=0.3.7 (from virtualenv)\n  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.17.0)\nRequirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.3.6)\nDownloading virtualenv-20.29.3-py3-none-any.whl (4.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: distlib, virtualenv\nSuccessfully installed distlib-0.3.9 virtualenv-20.29.3\ninstalling venv\ncreated virtual environment CPython3.10.12.final.0-64 in 805ms\n  creator CPython3Posix(dest=/kaggle/working/venv, clear=False, no_vcs_ignore=False, global=False)\n  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n    added seed packages: pip==25.0.1, setuptools==75.8.0, wheel==0.45.1\n  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n/kaggle/working\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\nLooking in indexes: https://download.pytorch.org/whl/cu121\nCollecting torch\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (780.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torchaudio\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting filelock (from torch)\n  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting typing-extensions>=4.8.0 (from torch)\n  Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\nCollecting networkx (from torch)\n  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\nCollecting jinja2 (from torch)\n  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\nCollecting fsspec (from torch)\n  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m118.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\nCollecting triton==3.1.0 (from torch)\n  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting sympy==1.13.1 (from torch)\n  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting numpy (from torchvision)\n  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\nCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\nCollecting MarkupSafe>=2.0 (from jinja2->torch)\n  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nDownloading https://download.pytorch.org/whl/pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nDownloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\nDownloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\nDownloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\nDownloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\nSuccessfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 pillow-11.0.0 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0 typing-extensions-4.12.2\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\nCollecting tensorflow[and-cuda]\n  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nCollecting absl-py>=1.0.0 (from tensorflow[and-cuda])\n  Downloading absl_py-2.2.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting astunparse>=1.6.0 (from tensorflow[and-cuda])\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\nCollecting flatbuffers>=24.3.25 (from tensorflow[and-cuda])\n  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\nCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow[and-cuda])\n  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting google-pasta>=0.1.1 (from tensorflow[and-cuda])\n  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\nCollecting libclang>=13.0.0 (from tensorflow[and-cuda])\n  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\nCollecting opt-einsum>=2.3.2 (from tensorflow[and-cuda])\n  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\nCollecting packaging (from tensorflow[and-cuda])\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow[and-cuda])\n  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting requests<3,>=2.21.0 (from tensorflow[and-cuda])\n  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from tensorflow[and-cuda]) (75.8.0)\nCollecting six>=1.12.0 (from tensorflow[and-cuda])\n  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting termcolor>=1.1.0 (from tensorflow[and-cuda])\n  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.10/site-packages (from tensorflow[and-cuda]) (4.12.2)\nCollecting wrapt>=1.11.0 (from tensorflow[and-cuda])\n  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\nCollecting grpcio<2.0,>=1.24.3 (from tensorflow[and-cuda])\n  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting tensorboard~=2.19.0 (from tensorflow[and-cuda])\n  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting keras>=3.5.0 (from tensorflow[and-cuda])\n  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: numpy<2.2.0,>=1.26.0 in ./venv/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.1.2)\nCollecting h5py>=3.11.0 (from tensorflow[and-cuda])\n  Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow[and-cuda])\n  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow[and-cuda])\n  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nCollecting nvidia-cublas-cu12==12.5.3.2 (from tensorflow[and-cuda])\n  Downloading nvidia_cublas_cu12-12.5.3.2-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.5.82 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_cupti_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-nvcc-cu12==12.5.82 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_nvcc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.5.82 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.5.82 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_runtime_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cudnn-cu12==9.3.0.75 (from tensorflow[and-cuda])\n  Downloading nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu12==11.2.3.61 (from tensorflow[and-cuda])\n  Downloading nvidia_cufft_cu12-11.2.3.61-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.6.82 (from tensorflow[and-cuda])\n  Downloading nvidia_curand_cu12-10.3.6.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.3.83 (from tensorflow[and-cuda])\n  Downloading nvidia_cusolver_cu12-11.6.3.83-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.1.3 (from tensorflow[and-cuda])\n  Downloading nvidia_cusparse_cu12-12.5.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.23.4 (from tensorflow[and-cuda])\n  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.5.82 (from tensorflow[and-cuda])\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\nCollecting rich (from keras>=3.5.0->tensorflow[and-cuda])\n  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\nCollecting namex (from keras>=3.5.0->tensorflow[and-cuda])\n  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\nCollecting optree (from keras>=3.5.0->tensorflow[and-cuda])\n  Downloading optree-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\nCollecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow[and-cuda])\n  Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\nCollecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow[and-cuda])\n  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\nCollecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow[and-cuda])\n  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow[and-cuda])\n  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\nCollecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow[and-cuda])\n  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow[and-cuda])\n  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\nCollecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow[and-cuda])\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow[and-cuda]) (2.1.5)\nCollecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow[and-cuda])\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\nCollecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.5.0->tensorflow[and-cuda])\n  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow[and-cuda])\n  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\nDownloading nvidia_cublas_cu12-12.5.3.2-py3-none-manylinux2014_x86_64.whl (363.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.3/363.3 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m137.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (22.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (24.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m148.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (895 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.7/895.7 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl (577.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.2/577.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.3.61-py3-none-manylinux2014_x86_64.whl (192.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.6.82-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.3.83-py3-none-manylinux2014_x86_64.whl (130.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.1.3-py3-none-manylinux2014_x86_64.whl (217.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.6/217.6 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading absl_py-2.2.0-py3-none-any.whl (276 kB)\nDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nDownloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\nDownloading gast-0.6.0-py3-none-any.whl (21 kB)\nDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\nDownloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m133.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\nDownloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\nDownloading requests-2.32.3-py3-none-any.whl (64 kB)\nDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\nDownloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\nDownloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\nDownloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\nDownloading idna-3.10-py3-none-any.whl (70 kB)\nDownloading Markdown-3.7-py3-none-any.whl (106 kB)\nDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\nDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\nDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\nDownloading optree-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (395 kB)\nDownloading rich-13.9.4-py3-none-any.whl (242 kB)\nDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\nDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nInstalling collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, pygments, protobuf, packaging, optree, opt-einsum, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, mdurl, markdown, idna, h5py, grpcio, gast, charset-normalizer, certifi, absl-py, tensorboard, requests, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, markdown-it-py, google-pasta, astunparse, rich, nvidia-cusolver-cu12, keras, tensorflow\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.1.105\n    Uninstalling nvidia-nvjitlink-cu12-12.1.105:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.1.105\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.2.106\n    Uninstalling nvidia-curand-cu12-10.3.2.106:\n      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorch 2.5.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.5.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.5.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.5.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.5.1+cu121 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.5.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.5.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.5.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.5.1+cu121 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.23.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed absl-py-2.2.0 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-3.9.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.8 nvidia-cublas-cu12-12.5.3.2 nvidia-cuda-cupti-cu12-12.5.82 nvidia-cuda-nvcc-cu12-12.5.82 nvidia-cuda-nvrtc-cu12-12.5.82 nvidia-cuda-runtime-cu12-12.5.82 nvidia-cudnn-cu12-9.3.0.75 nvidia-cufft-cu12-11.2.3.61 nvidia-curand-cu12-10.3.6.82 nvidia-cusolver-cu12-11.6.3.83 nvidia-cusparse-cu12-12.5.1.3 nvidia-nccl-cu12-2.23.4 nvidia-nvjitlink-cu12-12.5.82 opt-einsum-3.4.0 optree-0.14.1 packaging-24.2 protobuf-5.29.4 pygments-2.19.1 requests-2.32.3 rich-13.9.4 six-1.17.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 urllib3-2.3.0 werkzeug-3.1.3 wrapt-1.17.2\n--2025-03-23 11:57:21--  https://q4j3.c11.e2-5.dev/downloads/req.txt\nResolving q4j3.c11.e2-5.dev (q4j3.c11.e2-5.dev)... 207.199.149.243\nConnecting to q4j3.c11.e2-5.dev (q4j3.c11.e2-5.dev)|207.199.149.243|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1870 (1.8K) [text/plain]\nSaving to: ‘req.txt’\n\nreq.txt             100%[===================>]   1.83K  --.-KB/s    in 0s      \n\n2025-03-23 11:57:21 (752 MB/s) - ‘req.txt’ saved [1870/1870]\n\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\nCollecting absl-py==2.1.0 (from -r /kaggle/working/req.txt (line 1))\n  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting aiohappyeyeballs==2.3.5 (from -r /kaggle/working/req.txt (line 2))\n  Downloading aiohappyeyeballs-2.3.5-py3-none-any.whl.metadata (5.8 kB)\nCollecting aiohttp==3.10.3 (from -r /kaggle/working/req.txt (line 3))\n  Downloading aiohttp-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\nCollecting aiosignal==1.3.1 (from -r /kaggle/working/req.txt (line 4))\n  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: astunparse==1.6.3 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 5)) (1.6.3)\nCollecting async-timeout==4.0.3 (from -r /kaggle/working/req.txt (line 6))\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nCollecting attrs==24.2.0 (from -r /kaggle/working/req.txt (line 7))\n  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\nCollecting certifi==2024.7.4 (from -r /kaggle/working/req.txt (line 8))\n  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\nCollecting cffi==1.17.0 (from -r /kaggle/working/req.txt (line 9))\n  Downloading cffi-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting charset-normalizer==3.3.2 (from -r /kaggle/working/req.txt (line 10))\n  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\nCollecting click==8.1.7 (from -r /kaggle/working/req.txt (line 11))\n  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\nCollecting cryptography==43.0.0 (from -r /kaggle/working/req.txt (line 12))\n  Downloading cryptography-43.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\nCollecting Deprecated==1.2.14 (from -r /kaggle/working/req.txt (line 13))\n  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\nCollecting einops==0.8.0 (from -r /kaggle/working/req.txt (line 14))\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock==3.13.1 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 15)) (3.13.1)\nCollecting flatbuffers==24.3.25 (from -r /kaggle/working/req.txt (line 16))\n  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\nCollecting frozenlist==1.4.1 (from -r /kaggle/working/req.txt (line 17))\n  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting fsspec==2024.2.0 (from -r /kaggle/working/req.txt (line 18))\n  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: gast==0.6.0 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 19)) (0.6.0)\nCollecting gitdb==4.0.11 (from -r /kaggle/working/req.txt (line 20))\n  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\nCollecting GitPython==3.1.43 (from -r /kaggle/working/req.txt (line 21))\n  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: google-pasta==0.2.0 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 22)) (0.2.0)\nCollecting grpcio==1.65.4 (from -r /kaggle/working/req.txt (line 23))\n  Downloading grpcio-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting h5py==3.11.0 (from -r /kaggle/working/req.txt (line 24))\n  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting huggingface-hub==0.24.5 (from -r /kaggle/working/req.txt (line 25))\n  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\nCollecting idna==3.7 (from -r /kaggle/working/req.txt (line 26))\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nCollecting Jinja2==3.1.3 (from -r /kaggle/working/req.txt (line 27))\n  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\nCollecting keras==3.4.1 (from -r /kaggle/working/req.txt (line 28))\n  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\nCollecting kornia==0.7.3 (from -r /kaggle/working/req.txt (line 29))\n  Downloading kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\nCollecting kornia_rs==0.1.5 (from -r /kaggle/working/req.txt (line 30))\n  Downloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: libclang==18.1.1 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 31)) (18.1.1)\nCollecting Markdown==3.6 (from -r /kaggle/working/req.txt (line 32))\n  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: markdown-it-py==3.0.0 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 33)) (3.0.0)\nRequirement already satisfied: MarkupSafe==2.1.5 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 34)) (2.1.5)\nCollecting matrix-client==0.4.0 (from -r /kaggle/working/req.txt (line 35))\n  Downloading matrix_client-0.4.0-py2.py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: mdurl==0.1.2 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 36)) (0.1.2)\nCollecting ml-dtypes==0.4.0 (from -r /kaggle/working/req.txt (line 37))\n  Downloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: mpmath==1.3.0 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 38)) (1.3.0)\nCollecting multidict==6.0.5 (from -r /kaggle/working/req.txt (line 39))\n  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: namex==0.0.8 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 40)) (0.0.8)\nCollecting networkx==3.2.1 (from -r /kaggle/working/req.txt (line 41))\n  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\nCollecting numpy==1.26.3 (from -r /kaggle/working/req.txt (line 42))\n  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from -r /kaggle/working/req.txt (line 43))\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from -r /kaggle/working/req.txt (line 44))\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-nvcc-cu12==12.3.107 (from -r /kaggle/working/req.txt (line 45))\n  Downloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from -r /kaggle/working/req.txt (line 46))\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from -r /kaggle/working/req.txt (line 47))\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from -r /kaggle/working/req.txt (line 48))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from -r /kaggle/working/req.txt (line 49))\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from -r /kaggle/working/req.txt (line 50))\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from -r /kaggle/working/req.txt (line 51))\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from -r /kaggle/working/req.txt (line 52))\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from -r /kaggle/working/req.txt (line 53))\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.3.101 (from -r /kaggle/working/req.txt (line 54))\n  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 55)) (12.1.105)\nCollecting opt-einsum==3.3.0 (from -r /kaggle/working/req.txt (line 56))\n  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting optree==0.12.1 (from -r /kaggle/working/req.txt (line 57))\n  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\nCollecting packaging==24.1 (from -r /kaggle/working/req.txt (line 58))\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nCollecting pillow==10.2.0 (from -r /kaggle/working/req.txt (line 59))\n  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\nCollecting protobuf==4.25.4 (from -r /kaggle/working/req.txt (line 60))\n  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting psutil==6.0.0 (from -r /kaggle/working/req.txt (line 61))\n  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nCollecting pycparser==2.22 (from -r /kaggle/working/req.txt (line 62))\n  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\nCollecting PyGithub==2.3.0 (from -r /kaggle/working/req.txt (line 63))\n  Downloading PyGithub-2.3.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting Pygments==2.18.0 (from -r /kaggle/working/req.txt (line 64))\n  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\nCollecting PyJWT==2.9.0 (from -r /kaggle/working/req.txt (line 65))\n  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting PyNaCl==1.5.0 (from -r /kaggle/working/req.txt (line 66))\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\nCollecting PyYAML==6.0.2 (from -r /kaggle/working/req.txt (line 67))\n  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\nCollecting regex==2024.7.24 (from -r /kaggle/working/req.txt (line 68))\n  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\nRequirement already satisfied: requests==2.32.3 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 69)) (2.32.3)\nCollecting rich==13.7.1 (from -r /kaggle/working/req.txt (line 70))\n  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\nCollecting safetensors==0.4.4 (from -r /kaggle/working/req.txt (line 71))\n  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting scipy==1.14.0 (from -r /kaggle/working/req.txt (line 72))\n  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\nCollecting sentencepiece==0.2.0 (from -r /kaggle/working/req.txt (line 73))\n  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\nCollecting shellingham==1.5.4 (from -r /kaggle/working/req.txt (line 74))\n  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting six==1.16.0 (from -r /kaggle/working/req.txt (line 75))\n  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\nCollecting smmap==5.0.1 (from -r /kaggle/working/req.txt (line 76))\n  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\nCollecting soundfile==0.12.1 (from -r /kaggle/working/req.txt (line 77))\n  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\nCollecting spandrel==0.3.4 (from -r /kaggle/working/req.txt (line 78))\n  Downloading spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)\nCollecting sympy==1.12 (from -r /kaggle/working/req.txt (line 79))\n  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\nCollecting tensorboard==2.17.0 (from -r /kaggle/working/req.txt (line 80))\n  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: tensorboard-data-server==0.7.2 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 81)) (0.7.2)\nCollecting tensorflow==2.17.0 (from -r /kaggle/working/req.txt (line 82))\n  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in ./venv/lib/python3.10/site-packages (from -r /kaggle/working/req.txt (line 83)) (0.37.1)\nCollecting termcolor==2.4.0 (from -r /kaggle/working/req.txt (line 84))\n  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\nCollecting tokenizers==0.19.1 (from -r /kaggle/working/req.txt (line 85))\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.4.0+cu121 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.4.0+cu121\u001b[0m\u001b[31m\n\u001b[0mln: failed to create symbolic link '/kaggle/working/venv/bin/python': File exists\nln: failed to create symbolic link '/kaggle/working/venv/bin/python3': File exists\n/kaggle/working\nCloning into 'ComfyUI'...\nremote: Enumerating objects: 18282, done.\u001b[K\nremote: Counting objects: 100% (34/34), done.\u001b[K\nremote: Compressing objects: 100% (23/23), done.\u001b[K\nremote: Total 18282 (delta 19), reused 11 (delta 11), pack-reused 18248 (from 2)\u001b[K\nReceiving objects: 100% (18282/18282), 67.51 MiB | 26.18 MiB/s, done.\nResolving deltas: 100% (12259/12259), done.\n/kaggle/working/ComfyUI\nNote: switching to '7fc3ccdcc2fb1f20c4b7dd4aca374db952fd66df'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at 7fc3ccdc Add that nvidia cosmos is supported to the README.\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\nRequirement already satisfied: torch in /kaggle/working/venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\nCollecting torchsde (from -r requirements.txt (line 2))\n  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: torchvision in /kaggle/working/venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.20.1+cu121)\nRequirement already satisfied: torchaudio in /kaggle/working/venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.25.0 in /kaggle/working/venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.1.2)\nCollecting einops (from -r requirements.txt (line 6))\n  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\nCollecting transformers>=4.28.1 (from -r requirements.txt (line 7))\n  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\nCollecting tokenizers>=0.13.3 (from -r requirements.txt (line 8))\n  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting sentencepiece (from -r requirements.txt (line 9))\n  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\nCollecting safetensors>=0.4.2 (from -r requirements.txt (line 10))\n  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting aiohttp (from -r requirements.txt (line 11))\n  Downloading aiohttp-3.11.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\nCollecting pyyaml (from -r requirements.txt (line 12))\n  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: Pillow in /kaggle/working/venv/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (11.0.0)\nCollecting scipy (from -r requirements.txt (line 14))\n  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nCollecting tqdm (from -r requirements.txt (line 15))\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\nCollecting psutil (from -r requirements.txt (line 16))\n  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\nCollecting kornia>=0.7.1 (from -r requirements.txt (line 19))\n  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\nCollecting spandrel (from -r requirements.txt (line 20))\n  Downloading spandrel-0.4.1-py3-none-any.whl.metadata (15 kB)\nCollecting soundfile (from -r requirements.txt (line 21))\n  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: filelock in /kaggle/working/venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /kaggle/working/venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\nRequirement already satisfied: networkx in /kaggle/working/venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.3)\nRequirement already satisfied: jinja2 in /kaggle/working/venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\nRequirement already satisfied: fsspec in /kaggle/working/venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 1))\n  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 1))\n  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 1))\n  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 1))\n  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 1))\n  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /kaggle/working/venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\nRequirement already satisfied: triton==3.1.0 in /kaggle/working/venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /kaggle/working/venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /kaggle/working/venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1)) (12.5.82)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /kaggle/working/venv/lib/python3.10/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\nCollecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\nCollecting huggingface-hub<1.0,>=0.26.0 (from transformers>=4.28.1->-r requirements.txt (line 7))\n  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: packaging>=20.0 in /kaggle/working/venv/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (24.2)\nCollecting regex!=2019.12.17 (from transformers>=4.28.1->-r requirements.txt (line 7))\n  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\nRequirement already satisfied: requests in /kaggle/working/venv/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (2.32.3)\nCollecting aiohappyeyeballs>=2.3.0 (from aiohttp->-r requirements.txt (line 11))\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\nCollecting aiosignal>=1.1.2 (from aiohttp->-r requirements.txt (line 11))\n  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\nCollecting async-timeout<6.0,>=4.0 (from aiohttp->-r requirements.txt (line 11))\n  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\nCollecting attrs>=17.3.0 (from aiohttp->-r requirements.txt (line 11))\n  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\nCollecting frozenlist>=1.1.1 (from aiohttp->-r requirements.txt (line 11))\n  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nCollecting multidict<7.0,>=4.5 (from aiohttp->-r requirements.txt (line 11))\n  Downloading multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting propcache>=0.2.0 (from aiohttp->-r requirements.txt (line 11))\n  Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nCollecting yarl<2.0,>=1.17.0 (from aiohttp->-r requirements.txt (line 11))\n  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\nCollecting kornia_rs>=0.1.0 (from kornia>=0.7.1->-r requirements.txt (line 19))\n  Downloading kornia_rs-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nCollecting cffi>=1.0 (from soundfile->-r requirements.txt (line 21))\n  Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting pycparser (from cffi>=1.0->soundfile->-r requirements.txt (line 21))\n  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\nRequirement already satisfied: idna>=2.0 in /kaggle/working/venv/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp->-r requirements.txt (line 11)) (3.10)\nRequirement already satisfied: MarkupSafe>=2.0 in /kaggle/working/venv/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /kaggle/working/venv/lib/python3.10/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 7)) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /kaggle/working/venv/lib/python3.10/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 7)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /kaggle/working/venv/lib/python3.10/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 7)) (2025.1.31)\nDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\nDownloading einops-0.8.1-py3-none-any.whl (64 kB)\nDownloading transformers-4.50.0-py3-none-any.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m131.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\nDownloading aiohttp-3.11.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\nDownloading kornia-0.8.0-py2.py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading spandrel-0.4.1-py3-none-any.whl (305 kB)\nDownloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nDownloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\nDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\nDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\nDownloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\nDownloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\nDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\nDownloading kornia_rs-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\nDownloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\nDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\nDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\nDownloading pycparser-2.22-py3-none-any.whl (117 kB)\nInstalling collected packages: trampoline, sentencepiece, tqdm, scipy, safetensors, regex, pyyaml, pycparser, psutil, propcache, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multidict, kornia_rs, frozenlist, einops, attrs, async-timeout, aiohappyeyeballs, yarl, nvidia-cusolver-cu12, nvidia-cudnn-cu12, huggingface-hub, cffi, aiosignal, tokenizers, soundfile, aiohttp, transformers, torchsde, kornia, spandrel\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\nSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.3.0 cffi-1.17.1 einops-0.8.1 frozenlist-1.5.0 huggingface-hub-0.29.3 kornia-0.8.0 kornia_rs-0.1.8 multidict-6.2.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 propcache-0.3.0 psutil-7.0.0 pycparser-2.22 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 scipy-1.15.2 sentencepiece-0.2.0 soundfile-0.13.1 spandrel-0.4.1 tokenizers-0.21.1 torchsde-0.2.6 tqdm-4.67.1 trampoline-0.1.2 transformers-4.50.0 yarl-1.18.3\n/kaggle/working/ComfyUI/custom_nodes\nCloning into 'ComfyUI-Manager'...\nremote: Enumerating objects: 18604, done.\u001b[K\nremote: Counting objects: 100% (3606/3606), done.\u001b[K\nremote: Compressing objects: 100% (341/341), done.\u001b[K\nremote: Total 18604 (delta 3398), reused 3268 (delta 3265), pack-reused 14998 (from 3)\u001b[K\nReceiving objects: 100% (18604/18604), 27.00 MiB | 32.72 MiB/s, done.\nResolving deltas: 100% (13751/13751), done.\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\nAlready up to date.\n--2025-03-23 11:59:06--  https://raw.githubusercontent.com/wandaweb/jupyter-webui-tunneling/main/pinggy.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2112 (2.1K) [text/plain]\nSaving to: ‘/kaggle/working/pinggy.py’\n\n/kaggle/working/pin 100%[===================>]   2.06K  --.-KB/s    in 0s      \n\n2025-03-23 11:59:07 (26.0 MB/s) - ‘/kaggle/working/pinggy.py’ saved [2112/2112]\n\n/kaggle/working/ComfyUI/custom_nodes\n--2025-03-23 11:59:07--  https://gist.githubusercontent.com/city96/30743dfdfe129b331b5676a79c3a8a39/raw/ecb4f6f5202c20ea723186c93da308212ba04cfb/ComfyBootlegOffload.py\nResolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2164 (2.1K) [text/plain]\nSaving to: ‘ComfyBootlegOffload.py’\n\nComfyBootlegOffload 100%[===================>]   2.11K  --.-KB/s    in 0s      \n\n2025-03-23 11:59:07 (23.0 MB/s) - ‘ComfyBootlegOffload.py’ saved [2164/2164]\n\nCPU times: user 5.57 s, sys: 1.45 s, total: 7.03 s\nWall time: 5min 27s\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"--- \n# WebUI","metadata":{}},{"cell_type":"markdown","source":"## Start the WebUI with Pinggy\n* Wait for the GUI to start.  \n* Click the link that ends with .pinggy.link 😁\n* If generation is still running after the link expires in an hour, wait for the generation to complete and restart the WebUI code block to get a new link","metadata":{}},{"cell_type":"code","source":"# Starting the Web UI with pinggy\n\n%cd /kaggle/working/ComfyUI\n!python /kaggle/working/pinggy.py --command='/kaggle/working/venv/bin/python /kaggle/working/ComfyUI/main.py' --port=8188","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:04:23.291311Z","iopub.execute_input":"2025-03-23T12:04:23.291707Z","iopub.status.idle":"2025-03-23T12:05:21.958800Z","shell.execute_reply.started":"2025-03-23T12:04:23.291678Z","shell.execute_reply":"2025-03-23T12:05:21.957744Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\n8188\n/kaggle/working/venv/bin/python /kaggle/working/ComfyUI/main.py\nPort 8188 is free.\n/kaggle/working/venv/bin/python /kaggle/working/ComfyUI/main.py\nwaiting for output\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\n[START] Security scan\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\n[DONE] Security scan\n## ComfyUI-Manager: installing dependencies done.\n** ComfyUI startup time: 2025-03-23 12:04:24.506\n** Platform: Linux\n** Python version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n** Python executable: /kaggle/working/venv/bin/python\n** ComfyUI Path: /kaggle/working/ComfyUI\n** ComfyUI Base Folder Path: /kaggle/working/ComfyUI\n** User directory: /kaggle/working/ComfyUI/user\n** ComfyUI-Manager config path: /kaggle/working/ComfyUI/user/default/ComfyUI-Manager/config.ini\n** Log path: /kaggle/working/ComfyUI/user/comfyui.log\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\nAllocated port 4 for remote forward to localhost:8188\n[ComfyUI-Manager] Skipped fixing the 'comfyui-frontend-package' dependency because the ComfyUI is outdated.\n\nPrestartup times for custom nodes:\n   1.7 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n\n😁 😁 😁\nURL: http://rnpnh-34-27-50-212.a.free.pinggy.link\n😁 😁 😁\n\u001b[?1000l\u001b[?1002l\u001b[?1003l\u001b[?1006l\u001b[?2004l\u001b7\u001b[?47h\u001b[?1h\u001b=\u001b)0\u001b[H\u001b[2J\u001b[25;81H\u001b[1;1H\u001b[m\u001b]8;;\u001b\\                                                                                \u001b[2;1H                                                                                \u001b[3;1H                                                                                \u001b[4;1H                                                                                \u001b[5;1H                                                                                \u001b[6;1H                                                                                \u001b[7;1H                                                                                \u001b[8;1H                                                                                \u001b[9;1H                         ┌────────────────────────────┐                         \u001b[10;1H                         │                            │                         \u001b[11;1H                         │ Wait while we prepare the  │                         \u001b[12;1H                         │             UI             │                         \u001b[13;1H                         │                            │                         \u001b[14;1H                         │                            │                         \u001b[15;1H                         │                            │                         \u001b[16;1H                         └────────────────────────────┘                         \u001b[17;1H                                                                                \u001b[18;1H                                                                                \u001b[19;1H                                                                                \u001b[20;1H                                                                                \u001b[21;1H                                                                                \u001b[22;1H                                                                                \u001b[23;1H                                                                                \u001b[24;1H                                                                                \u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[1;28H\u001b[m\u001b]8;;\u001b\\You\u001b[1;32Hare\u001b[1;36Hnot\u001b[1;40Hauthenticated.\u001b[2;1HYour\u001b[2;6Htunnel\u001b[2;13Hwill\u001b[2;18Hexpire\u001b[2;25Hin\u001b[2;28H60\u001b[2;31Hminutes.\u001b[2;40HUpgrade\u001b[2;48Hto\u001b[2;51HPinggy\u001b[2;58HPro\u001b[2;62Hto\u001b[2;65Hget\u001b[2;69Hunrestricted\u001b[3;23Htunnels.\u001b[3;32Hhttps://dashboard.pinggy.io\u001b[5;4Hhttp://rnpnh-34-27-50-212.a.free.pinggy.link\u001b[6;4Hhttps://rnpnh-34-27-50-212.a.free.pinggy.link\u001b[9;26H                              \u001b[10;26H \u001b[10;55H \u001b[11;26H \u001b[11;28H    \u001b[11;33H     \u001b[11;39H  \u001b[11;42H       \u001b[11;50H   \u001b[11;55H \u001b[12;26H \u001b[12;40H  \u001b[12;55H \u001b[13;26H \u001b[13;55H \u001b[14;26H \u001b[14;55H \u001b[15;26H \u001b[15;55H \u001b[16;26H                              \u001b[24;28HPress\u001b[24;34H`h`\u001b[24;38Hfor\u001b[24;42Hkeybindings\u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[m\u001b]8;;\u001b\\\u001b[H\u001b[2J\u001b[1;28H\u001b[m\u001b]8;;\u001b\\You\u001b[1;32Hare\u001b[1;36Hnot\u001b[1;40Hauthenticated.\u001b[2;1HYour\u001b[2;6Htunnel\u001b[2;13Hwill\u001b[2;18Hexpire\u001b[2;25Hin\u001b[2;28H60\u001b[2;31Hminutes.\u001b[2;40HUpgrade\u001b[2;48Hto\u001b[2;51HPinggy\u001b[2;58HPro\u001b[2;62Hto\u001b[2;65Hget\u001b[2;69Hunrestricted\u001b[3;23Htunnels.\u001b[3;32Hhttps://dashboard.pinggy.io\u001b[5;4Hhttp://rnpnh-34-27-50-212.a.free.pinggy.link\u001b[6;4Hhttps://rnpnh-34-27-50-212.a.free.pinggy.link\u001b[24;28HPress\u001b[24;34H`h`\u001b[24;38Hfor\u001b[24;42Hkeybindings\u001b[25;81H\nCheckpoint files will always be loaded safely.\nTotal VRAM 15095 MB, total RAM 32103 MB\npytorch version: 2.5.1+cu121\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 Tesla T4 : cudaMallocAsync\nUsing pytorch attention\n[Prompt Server] web root: /kaggle/working/ComfyUI/web\n### Loading: ComfyUI-Manager (V3.31.7)\n[ComfyUI-Manager] network_mode: public\n### ComfyUI Revision: 3056 [7fc3ccdc] *DETACHED | Released on '2025-01-16'\n\nImport times for custom nodes:\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/websocket_image_save.py\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyBootlegOffload.py\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\nFETCH ComfyRegistry Data: 5/79\nFETCH ComfyRegistry Data: 10/79\nFETCH ComfyRegistry Data: 15/79\nFETCH ComfyRegistry Data: 20/79\nFETCH ComfyRegistry Data: 25/79\nFETCH ComfyRegistry Data: 30/79\nFETCH ComfyRegistry Data: 35/79\nFETCH ComfyRegistry Data: 40/79\nFETCH ComfyRegistry Data: 45/79\nFETCH ComfyRegistry Data: 50/79\nFETCH ComfyRegistry Data: 55/79\ngot prompt\nmodel weight dtype torch.float16, manual cast: None\nmodel_type EPS\nFETCH ComfyRegistry Data: 60/79\nUsing pytorch attention in VAE\nUsing pytorch attention in VAE\nVAE load device: cuda:0, offload device: cpu, dtype: torch.float32\nRequested to load SDXLClipModel\nloaded completely 9.5367431640625e+25 1560.802734375 True\nCLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\nFETCH ComfyRegistry Data: 65/79\nRequested to load SDXL\nFETCH ComfyRegistry Data: 70/79\nloaded completely 9.5367431640625e+25 4897.0483474731445 True\n 55%|███████████████████████▋                   | 11/20 [00:02<00:01,  5.22it/s]FETCH ComfyRegistry Data: 75/79\n100%|███████████████████████████████████████████| 20/20 [00:04<00:00,  4.95it/s]\nRequested to load AutoencoderKL\nloaded completely 9.5367431640625e+25 319.11416244506836 True\nPrompt executed in 11.61 seconds\nFETCH ComfyRegistry Data [DONE]\n[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\nFETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n[ComfyUI-Manager] All startup tasks have been completed.\nConnection to a.pinggy.io closed by remote host.\nConnection to a.pinggy.io closed.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Start the WebUI with Zrok\n\n### Install Zrok","metadata":{}},{"cell_type":"code","source":"# Install Zrok (only needs to run once)\n\n!mkdir /kaggle/working/zrok\n%cd /kaggle/working/zrok\n!wget https://github.com/openziti/zrok/releases/download/v0.4.23/zrok_0.4.23_linux_amd64.tar.gz\n!tar -xvf ./zrok*.gz \n!chmod a+x /kaggle/working/zrok/zrok ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:05:26.397847Z","iopub.execute_input":"2025-03-23T12:05:26.398196Z","iopub.status.idle":"2025-03-23T12:05:27.997971Z","shell.execute_reply.started":"2025-03-23T12:05:26.398164Z","shell.execute_reply":"2025-03-23T12:05:27.996941Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/zrok\n--2025-03-23 12:05:26--  https://github.com/openziti/zrok/releases/download/v0.4.23/zrok_0.4.23_linux_amd64.tar.gz\nResolving github.com (github.com)... 140.82.113.4\nConnecting to github.com (github.com)|140.82.113.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/515311500/53a2fa87-54f7-4511-975d-fd33dded857c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250323%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250323T120526Z&X-Amz-Expires=300&X-Amz-Signature=dc06218fea6f40709cc0988e4a729a62afd3ba31f167dda29cd9c6336c6b158d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dzrok_0.4.23_linux_amd64.tar.gz&response-content-type=application%2Foctet-stream [following]\n--2025-03-23 12:05:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/515311500/53a2fa87-54f7-4511-975d-fd33dded857c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250323%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250323T120526Z&X-Amz-Expires=300&X-Amz-Signature=dc06218fea6f40709cc0988e4a729a62afd3ba31f167dda29cd9c6336c6b158d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dzrok_0.4.23_linux_amd64.tar.gz&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 25141044 (24M) [application/octet-stream]\nSaving to: ‘zrok_0.4.23_linux_amd64.tar.gz’\n\nzrok_0.4.23_linux_a 100%[===================>]  23.98M   143MB/s    in 0.2s    \n\n2025-03-23 12:05:27 (143 MB/s) - ‘zrok_0.4.23_linux_amd64.tar.gz’ saved [25141044/25141044]\n\nCHANGELOG.md\nLICENSE\nREADME.md\nzrok\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Create a Zrok account\nEnter your email address in the email variable","metadata":{}},{"cell_type":"code","source":"email = '####@gmail.com' # replace with your email\n\n# --------------\n\ncmd = '/kaggle/working/zrok/zrok invite'\nlog = '/kaggle/working/zrok/log.txt'\n\n!pip install pexpect\n!touch $log\n\nimport pexpect\nimport time\nchild = pexpect.spawn('bash')\nchild.sendline(f'{cmd} | tee {log}')\nchild.expect('enter and confirm your email address...')\ntime.sleep(1); child.sendline(email); time.sleep(1); child.send(chr(9)); time.sleep(1)\nchild.sendline(email); time.sleep(1); child.send('\\n'); time.sleep(1); child.send(chr(9))\ntime.sleep(1); child.send('\\r\\n'); time.sleep(2); child.close()\n!cat $log\n!rm $log","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Enable Zrok \nPaste your Zrok token in the token variable","metadata":{}},{"cell_type":"code","source":"# Enable Zrok (needs to run once per instance)\n# Paste your Zrok token in the token variable\n\ntoken = \"\"\n!chmod a+x /kaggle/working/zrok/zrok \n!/kaggle/working/zrok/zrok enable $token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:07:24.504974Z","iopub.execute_input":"2025-03-23T12:07:24.505316Z","iopub.status.idle":"2025-03-23T12:07:31.511213Z","shell.execute_reply.started":"2025-03-23T12:07:24.505290Z","shell.execute_reply":"2025-03-23T12:07:31.510075Z"}},"outputs":[{"name":"stdout","text":"\u001b]10;?\u001b\\\u001b[6n\u001b]11;?\u001b\\\u001b[6n[   5.712]    INFO main.(*enableCommand).run: the zrok environment was successfully enabled...\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Start the WebUI with Zrok","metadata":{}},{"cell_type":"code","source":"# Start the WebUI with Zrok\n%cd /kaggle/working/ComfyUI\ncommand = '/kaggle/working/venv/bin/python /kaggle/working/ComfyUI/main.py'\nport = '8188'\n# ------------------------\n\n!chmod a+x /kaggle/working/zrok/zrok \ncmd = f'{command} & /kaggle/working/zrok/zrok share public http://localhost:{port} --headless'\nget_ipython().system(cmd)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:08:54.560888Z","iopub.execute_input":"2025-03-23T12:08:54.561216Z","iopub.status.idle":"2025-03-23T12:32:49.429588Z","shell.execute_reply.started":"2025-03-23T12:08:54.561187Z","shell.execute_reply":"2025-03-23T12:32:49.428475Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\n[START] Security scan\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\n[DONE] Security scan\n## ComfyUI-Manager: installing dependencies done.\n** ComfyUI startup time: 2025-03-23 12:08:55.765\n** Platform: Linux\n** Python version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n** Python executable: /kaggle/working/venv/bin/python\n** ComfyUI Path: /kaggle/working/ComfyUI\n** ComfyUI Base Folder Path: /kaggle/working/ComfyUI\n** User directory: /kaggle/working/ComfyUI/user\n** ComfyUI-Manager config path: /kaggle/working/ComfyUI/user/default/ComfyUI-Manager/config.ini\n** Log path: /kaggle/working/ComfyUI/user/comfyui.log\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\nError in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'log'\n[ComfyUI-Manager] Skipped fixing the 'comfyui-frontend-package' dependency because the ComfyUI is outdated.\n\nPrestartup times for custom nodes:\n   1.7 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n\n[   2.853]    INFO sdk-golang/ziti.(*listenerManager).createSessionWithBackoff: {session token=[03e9b393-699d-4efd-bb13-aa9be1b5ded5]} new service session\n[   3.015]    INFO main.(*sharePublicCommand).run: access your zrok share at the following endpoints:\n https://ow1xat981cjk.share.zrok.io\nCheckpoint files will always be loaded safely.\nTotal VRAM 15095 MB, total RAM 32103 MB\npytorch version: 2.5.1+cu121\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 Tesla T4 : cudaMallocAsync\nUsing pytorch attention\n[Prompt Server] web root: /kaggle/working/ComfyUI/web\n### Loading: ComfyUI-Manager (V3.31.7)\n[ComfyUI-Manager] network_mode: public\n### ComfyUI Revision: 3056 [7fc3ccdc] *DETACHED | Released on '2025-01-16'\n\nImport times for custom nodes:\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/websocket_image_save.py\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyBootlegOffload.py\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\nFETCH ComfyRegistry Data: 5/79\nFETCH ComfyRegistry Data: 10/79\nFETCH ComfyRegistry Data: 15/79\nFETCH ComfyRegistry Data: 20/79\nFETCH ComfyRegistry Data: 25/79\n[  20.368]    INFO main.(*sharePublicCommand).run: [] -> GET /\n[  20.548]    INFO main.(*sharePublicCommand).run: [] -> GET /user.css\n[  20.662]    INFO main.(*sharePublicCommand).run: [] -> GET /materialdesignicons.min.css\n[  21.942]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/index-DjNHn37O.js\n[  21.942]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/index-t-sFBuUC.css\nFETCH ComfyRegistry Data: 30/79\nFETCH ComfyRegistry Data: 35/79\nFETCH ComfyRegistry Data: 40/79\nFETCH ComfyRegistry Data: 45/79\nFETCH ComfyRegistry Data: 50/79\nFETCH ComfyRegistry Data: 55/79\n[  37.113]    INFO main.(*sharePublicCommand).run: [] -> GET /api/users\n[  37.126]    INFO main.(*sharePublicCommand).run: [] -> GET /favicon.ico\n[  37.264]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/GraphView-HVeNbkaW.js\n[  37.264]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/index-jXPKy3pP.js\n[  37.276]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/GraphView-CIRWBKTm.css\n[  37.869]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/index-5HFeZax4.js\n[  37.935]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/index-B-aVupP5.js\n[  38.085]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/keybindingService-Bx7YdkXn.js\n[  38.089]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/serverConfigStore-CvyKFVuP.js\n[  38.600]    INFO main.(*sharePublicCommand).run: [] -> GET /api/settings\nFETCH ComfyRegistry Data: 60/79\n[  38.693]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/primeicons-C6QP2o4f.woff2\n[  38.771]    INFO main.(*sharePublicCommand).run: [] -> GET /api/userdata?dir=workflows&recurse=true&split=false&full_info=true\n[  38.922]    INFO main.(*sharePublicCommand).run: [] -> GET /api/extensions\n[  39.088]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/index-BRhY6FpL.css\n[  39.095]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/index-Bordpmzt.js\nFETCH ComfyRegistry Data: 65/79\n[  43.892]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/model-manager.js\n[  43.897]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/snapshot.js\n[  43.903]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/comfyui-manager.js\nFETCH ComfyRegistry Data: 70/79\n[  44.072]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/comfyui-share-copus.js\n[  44.130]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/cm-api.js\n[  44.229]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/custom-nodes-manager.js\n[  44.273]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/components-manager.js\n[  44.283]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/popover-helper.js\n[  44.431]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/turbogrid.esm.js\n[  44.441]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/comfyui-share-common.js\n[  44.460]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/comfyui-share-openart.js\n[  44.619]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/common.js\n[  44.686]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/workflow-metadata.js\n[  44.776]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/node_fixer.js\n[  44.838]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/comfyui-share-youml.js\n[  44.930]    INFO main.(*sharePublicCommand).run: [] -> GET /scripts/app.js\n[  44.966]    INFO main.(*sharePublicCommand).run: [] -> GET /scripts/api.js\n[  44.989]    INFO main.(*sharePublicCommand).run: [] -> GET /scripts/ui.js\n[  45.081]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/core/groupNode.js\n[  45.142]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/model-manager.css\n[  45.143]    INFO main.(*sharePublicCommand).run: [] -> GET /extensions/ComfyUI-Manager/custom-nodes-manager.css\n[  45.235]    INFO main.(*sharePublicCommand).run: [] -> GET /api/manager/version\n[  45.236]    INFO main.(*sharePublicCommand).run: [] -> GET /api/manager/policy/component\n[  45.386]    INFO main.(*sharePublicCommand).run: [] -> GET /api/manager/share_option\n[  45.451]    INFO main.(*sharePublicCommand).run: [] -> GET /api/customnode/installed\n[  45.604]    INFO main.(*sharePublicCommand).run: [] -> GET /api/system_stats\n[  45.619]    INFO main.(*sharePublicCommand).run: [] -> GET /ws\n[  45.762]    INFO main.(*sharePublicCommand).run: [] -> GET /api/object_info\n[  46.457]    INFO main.(*sharePublicCommand).run: [] -> GET /api/userdata/comfy.templates.json\n[  46.457]    INFO main.(*sharePublicCommand).run: [] -> GET /scripts/ui/components/buttonGroup.js\n[  46.458]    INFO main.(*sharePublicCommand).run: [] -> POST /api/manager/component/loads\nFETCH ComfyRegistry Data: 75/79\n[  46.617]    INFO main.(*sharePublicCommand).run: [] -> GET /scripts/ui/components/button.js\n[  46.846]    INFO main.(*sharePublicCommand).run: [] -> GET /fonts/materialdesignicons-webfont.woff2?v=7.4.47\n[  47.789]    INFO main.(*sharePublicCommand).run: [] -> GET /api/experiment/models\n[  47.818]    INFO main.(*sharePublicCommand).run: [] -> GET /assets/sorted-custom-node-map.json\nFETCH ComfyRegistry Data [DONE]\n[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\nFETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n[ComfyUI-Manager] All startup tasks have been completed.\n[ 106.255]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 167.253]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 227.771]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 254.201]    INFO main.(*sharePublicCommand).run: [] -> POST /api/prompt\ngot prompt\nmodel weight dtype torch.float16, manual cast: None\nmodel_type EPS\nUsing pytorch attention in VAE\nUsing pytorch attention in VAE\nVAE load device: cuda:0, offload device: cpu, dtype: torch.float32\nRequested to load SDXLClipModel\nloaded completely 9.5367431640625e+25 1560.802734375 True\nCLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\nRequested to load SDXL\nloaded completely 9.5367431640625e+25 4897.0483474731445 True\n100%|███████████████████████████████████████████| 20/20 [00:13<00:00,  1.45it/s]\nRequested to load AutoencoderKL\nloaded completely 9.5367431640625e+25 319.11416244506836 True\nPrompt executed in 22.69 seconds\n[ 338.306]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 399.277]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 460.284]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 521.401]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 582.274]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 643.310]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 704.297]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 765.273]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 826.317]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 887.527]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[ 948.308]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[1009.308]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[1070.284]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[1131.314]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[1164.260]    INFO main.(*sharePublicCommand).run: [] -> GET /api/view?filename=ComfyUI_00002_.png&subfolder=&type=output&rand=0.9265956382503113\n[1192.042]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[1199.475]    INFO main.(*sharePublicCommand).run: [] -> POST /api/prompt\ngot prompt\n100%|███████████████████████████████████████████| 20/20 [00:17<00:00,  1.14it/s]\nPrompt executed in 20.94 seconds\n[1282.356]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[1343.287]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n[1367.002]    INFO main.(*sharePublicCommand).run: [] -> GET /api/view?filename=ComfyUI_00003_.png&subfolder=&type=output&rand=0.875636937103506\n[1404.312]    INFO main.(*sharePublicCommand).run: [] -> GET /ws?clientId=b85494c555e24b9e8204c1278f09f2ee\n^C\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"---\n# Model Management","metadata":{}},{"cell_type":"markdown","source":"## Install a model\n\nCopy the model URL to the model_url field. Make sure the model can be accessed publicly, without being signed into a website.","metadata":{}},{"cell_type":"code","source":"#### Install a model in permanent storage\n# Make sure Persistence is set to \"Files only\" or \"Variables and Files\"\nmodel_url = 'https://civitai.com/api/download/models/782002'\nmodel_name = 'JuggernautXL.safetensors'\n\n%cd $checkpoints\nget_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{"execution":{"iopub.status.busy":"2025-03-23T12:00:47.758798Z","iopub.execute_input":"2025-03-23T12:00:47.759134Z","iopub.status.idle":"2025-03-23T12:01:43.103409Z","shell.execute_reply.started":"2025-03-23T12:00:47.759104Z","shell.execute_reply":"2025-03-23T12:01:43.102328Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install a LoRA in permanent storage\nmodel_url = 'https://civitai.com/api/download/models/137124?type=Model&format=SafeTensor'\nmodel_name = 'DreamArt.safetensors'\n\n%cd /kaggle/working/ComfyUI/models/loras\nget_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install a model in temporary storage\n#model_url = 'https://civitai.com/api/download/models/160191?type=Model&format=SafeTensor&size=full&fp=fp16'\n#model_name = 'YamersRealism.safetensors'\nmodel_url = 'https://civitai.com/api/download/models/456751'\nmodel_name = 'HelloWorld-XL.safetensors' \n\n%cd $temp_models\nget_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Download a model for a custom node","metadata":{}},{"cell_type":"code","source":"model_folder = '/kaggle/working/ComfyUI/custom_nodes/my_node/models'\nmodel_url = ''\nmodel_name = 'model.safetensors'\n\n%cd $model_folder\nget_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# File Browser","metadata":{}},{"cell_type":"markdown","source":"## Install FileBrowser","metadata":{}},{"cell_type":"code","source":"%cd /kaggle\n!wget https://github.com/filebrowser/filebrowser/releases/download/v2.27.0/linux-amd64-filebrowser.tar.gz\n!tar xvfz linux-amd64-filebrowser.tar.gz\n!chmod a+x /kaggle/filebrowser\n!/kaggle/filebrowser config init \n!/kaggle/filebrowser config set --auth.method=noauth > /dev/null\n!/kaggle/filebrowser config set --branding.theme=dark > /dev/null\n!/kaggle/filebrowser users add admin admin \n!/kaggle/filebrowser config export \"/kaggle/config.json\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Run FileBrowser","metadata":{}},{"cell_type":"code","source":"%cd /kaggle\n!chmod a+x /kaggle/filebrowser\n\n!python /kaggle/working/pinggy.py --command='/kaggle/filebrowser -c \"/kaggle/working/config.json\"' --port=8080","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Delete a model","metadata":{}},{"cell_type":"code","source":"# List permanent models\n!ls -la $checkpoints\n\n# Delete a model\nmodel_to_delete = '/kaggle/working/ComfyUI/models/checkpoints/model.safetensors'\n!rm $model_to_delete","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the size of a model\n!du -sh /kaggle/working/ComfyUI/models/loras/harrlogos.safetensors","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Delete everything in the working folder","metadata":{}},{"cell_type":"code","source":"# Delete the working folder\n!rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:55:23.137688Z","iopub.execute_input":"2025-03-10T00:55:23.137982Z","iopub.status.idle":"2025-03-10T00:55:25.446201Z","shell.execute_reply.started":"2025-03-10T00:55:23.137957Z","shell.execute_reply":"2025-03-10T00:55:25.445118Z"}},"outputs":[],"execution_count":null}]}