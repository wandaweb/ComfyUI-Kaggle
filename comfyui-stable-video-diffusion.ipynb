{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pogscafe/comfyui-stable-video-diffusion?scriptVersionId=226725174\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Installation\nThe notebook requres a GPU Accelerator to run. To keep the files saved for the next run, make sure Persistence is set to \"Files only\" or \"Variables and Files\".  \nFor examples, have a look at our [SVD quickstart guide](https://www.pogs.cafe/content/svd-comfyui-kaggle).\n\n### If the video preview doesn't show up after generation, use File Browser to download the video. The output folder is:  /kaggle/working/ComfyUI/output","metadata":{}},{"cell_type":"code","source":"# --- Parameters --- #\n\n# If set to false, ComfyUI and ComfyUI Manager will not be updated after the initial install.\n# Set to true to update.\nupdate_comfy = False\nupdate_manager = False\ninstall_sdxl_model = True\n\n# SDXL model that will be saved to permanent storage. Used for text-to-image.\nsdxl_model_url = 'https://civitai.com/api/download/models/238308?type=Model&format=SafeTensor&size=pruned&fp=fp16'\nsdxl_model_name = 'AlbedoBase.safetensors'\n\n# Stable video diffusion model that will be saved to permanent storage.\n# Used for image-to-video.\nvideo_model_url_s = 'https://huggingface.co/becausecurious/stable-video-diffusion-img2vid-fp16/resolve/main/svd-fp16.safetensors?download=true'\nvideo_model_name_s = 'svd-fp16.safetensors'\nvideo_model_url = 'https://huggingface.co/becausecurious/stable-video-diffusion-img2vid-fp16/resolve/main/svd_xt-fp16.safetensors?download=true'\nvideo_model_name = 'svd_xt-fp16.safetensors'\n\n# ------------------- #\n\nfrom os import path\n\n%cd /kaggle/working\n!git clone https://github.com/comfyanonymous/ComfyUI.git\n%cd ComfyUI\n!git checkout 66831eb6e96cd974fb2d0fc4f299b23c6af16685\n\nif update_comfy:\n    get_ipython().system('git pull')\n!pip install -r requirements.txt\n\nworking_folder = '/kaggle/working'\ntemp_folder = '/kaggle/temp'\ncheckpoints =  f'{working_folder}/ComfyUI/models/checkpoints'\nloras = f'{working_folder}/ComfyUI/models/loras'\ntemp_loras_link = loras + '/temp-loras'\ntemp_loras = f'{temp_folder}/temp-loras'\ntemp_models_link = checkpoints + '/temp-models'\ntemp_models = f'{temp_folder}/temp-models'\ncustom_nodes = f'{working_folder}/ComfyUI/custom_nodes'\noutputs = f'{working_folder}/ComfyUI/output'\nzip_outputs = f'{working_folder}/outputs'\n\n!mkdir $temp_folder\n!mkdir $temp_models\n!mkdir $temp_loras\n\nif not path.exists(temp_models_link):\n    get_ipython().system(f'ln -s {temp_models} {checkpoints}')\nif not path.exists(temp_loras_link):\n    get_ipython().system(f'ln -s {temp_loras} {loras}')\n    \n!mamba install openssh -y\n\n# Install the node manager\n%cd $working_folder/ComfyUI/custom_nodes\n!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n%cd ComfyUI-Manager\nif update_manager:\n    get_ipython().system('git pull')\n!pip install -r requirements.txt\n\n# Install initial models\n%cd $checkpoints\nget_ipython().system(f'wget -O \"{video_model_name}\" \"{video_model_url}\"')\nget_ipython().system(f'wget -O \"{video_model_name_s}\" \"{video_model_url_s}\"')\nif install_sdxl_model and not path.exists(f'{checkpoints}/{sdxl_model_name}'):\n    get_ipython().system(f'wget -O \"{sdxl_model_name}\" \"{sdxl_model_url}\"')\n\n# Install an initial LoRA\n%cd $loras\nmodel_url = 'https://civitai.com/api/download/models/137124?type=Model&format=SafeTensor'\nmodel_name = 'DreamArt.safetensors'\nif not path.exists(f'{loras}/{model_name}'):\n    get_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')\n\n# Install the logic nodes\n%cd $custom_nodes\n!git clone https://github.com/theUpsider/ComfyUI-Logic.git\n    \n# Install VideoHelperSuite nodes\n%cd $custom_nodes\n!rm -rf ComfyUI-VideoHelperSuite\nget_ipython().system(f'wget -O \"videohelpersuite.zip\" \"https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/archive/4de52b66c809fb48b69d03019935da7a64ac40a4.zip\"')\nimport shutil\nshutil.unpack_archive(\"videohelpersuite.zip\", \".\", \"zip\") \n!mv ComfyUI-VideoHelperSuite* ComfyUI-VideoHelperSuite\n%cd ComfyUI-VideoHelperSuite\n\n# Frame interpolation nodes\n%cd $custom_nodes\n!git clone https://github.com/Fannovel16/ComfyUI-Frame-Interpolation\n%cd ComfyUI-Frame-Interpolation\n!git pull\n!python install.py\n\n# Modded nodes, used for math in the text-to-video and image-to-video workflow\n%cd $custom_nodes\n!git clone https://github.com/Derfuu/Derfuu_ComfyUI_ModdedNodes\n%cd Derfuu_ComfyUI_ModdedNodes\n!git checkout 6af9d06632e30b9b00eced4811cb61f52171549e\n\n!pip install --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n!pip install --force-reinstall numpy==1.22","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Start the WebUI\n\nWorkflows can be found on https://github.com/wandaweb/ComfyUI-Kaggle/tree/main/sample-workflows","metadata":{}},{"cell_type":"markdown","source":"**Option 1: Starting the Web UI with Pinggy**  \n* Wait for the UI to start.  \n* Click the link that ends with .pinggy.link 😁\n* If generation is still running after the link expires in an hour, wait for the generation to complete and restart the WebUI code block to get a new link\n* If the generation completed successfully, but the video didn't show up in the preview, you can find it in the output folder","metadata":{}},{"cell_type":"code","source":"# Starting the Web UI with pinggy\n\nfrom multiprocessing import Process\nimport sys\nimport time\n\n!touch log.txt\nopen('log.txt', 'w').close()\n\ndef run_app():\n    cmd = f\"python {working_folder}/ComfyUI/main.py & ssh -o StrictHostKeyChecking=no -p 80 -R0:localhost:8188 a.pinggy.io > log.txt\"\n    get_ipython().system(cmd)\n    \ndef print_url():\n    print(\"waiting for output\")\n    time.sleep(2)\n    sys.stdout.flush()\n    \n    found = False\n    with open('log.txt', 'r') as file:\n        end_word = '.pinggy.link'\n        for line in file:\n            start_index = line.find(\"http:\")\n            if start_index != -1:\n                end_index = line.find(end_word, start_index)\n                if end_index != -1:\n                    print(\"😁 😁 😁\")\n                    print(\"URL: \" + line[start_index:end_index + len(end_word)])\n                    print(\"😁 😁 😁\")\n                    found = True\n    if not found:\n        print_url()\n    else:\n        with open('log.txt', 'r') as file:\n            for line in file:\n                print(line)\n    \np_app = Process(target=run_app)\np_url = Process(target=print_url)\np_app.start()\np_url.start()\np_app.join()\np_url.join()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T03:33:48.485759Z","iopub.execute_input":"2025-03-10T03:33:48.486044Z","iopub.status.idle":"2025-03-10T03:56:06.677956Z","shell.execute_reply.started":"2025-03-10T03:33:48.486016Z","shell.execute_reply":"2025-03-10T03:56:06.676092Z"}},"outputs":[{"name":"stdout","text":"waiting for output\nWarning: Permanently added '[a.pinggy.io]:80' (RSA) to the list of known hosts.\n[START] Security scan\nwaiting for output\n\u001b[33mWARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n\u001b[0mAllocated port 7 for remote forward to localhost:8188\n[DONE] Security scan\nFailed to execute startup-script: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager/prestartup_script.py / module 'folder_paths' has no attribute 'get_user_directory'\n\nPrestartup times for custom nodes:\n   2.6 seconds (PRESTARTUP FAILED): /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n\n😁 😁 😁\nURL: http://rnyni-34-55-81-164.a.free.pinggy.link\n😁 😁 😁\n\u001b[?1000l\u001b[?1002l\u001b[?1003l\u001b[?1006l\u001b[?2004l\u001b7\u001b[?47h\u001b[?1h\u001b=\u001b)0\u001b[H\u001b[2J\u001b[25;81H\u001b[1;1H\u001b[m\u001b]8;;\u001b\\                                                                                \u001b[2;1H                                                                                \u001b[3;1H                                                                                \u001b[4;1H                                                                                \u001b[5;1H                                                                                \u001b[6;1H                                                                                \u001b[7;1H                                                                                \u001b[8;1H                                                                                \u001b[9;1H                         ┌────────────────────────────┐                         \u001b[10;1H                         │                            │                         \u001b[11;1H                         │ Wait while we prepare the  │                         \u001b[12;1H                         │             UI             │                         \u001b[13;1H                         │                            │                         \u001b[14;1H                         │                            │                         \u001b[15;1H                         │                            │                         \u001b[16;1H                         └────────────────────────────┘                         \u001b[17;1H                                                                                \u001b[18;1H                                                                                \u001b[19;1H                                                                                \u001b[20;1H                                                                                \u001b[21;1H                                                                                \u001b[22;1H                                                                                \u001b[23;1H                                                                                \u001b[24;1H                                                                                \u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[m\u001b]8;;\u001b\\\u001b[H\u001b[2J\u001b[9;26H\u001b[m\u001b]8;;\u001b\\┌────────────────────────────┐\u001b[10;26H│\u001b[10;55H│\u001b[11;26H│\u001b[11;28HWait\u001b[11;33Hwhile\u001b[11;39Hwe\u001b[11;42Hprepare\u001b[11;50Hthe\u001b[11;55H│\u001b[12;26H│\u001b[12;40HUI\u001b[12;55H│\u001b[13;26H│\u001b[13;55H│\u001b[14;26H│\u001b[14;55H│\u001b[15;26H│\u001b[15;55H│\u001b[16;26H└────────────────────────────┘\u001b[25;81H\u001b[25;81H\u001b[1;28H\u001b[m\u001b]8;;\u001b\\You\u001b[1;32Hare\u001b[1;36Hnot\u001b[1;40Hauthenticated.\u001b[2;1HYour\u001b[2;6Htunnel\u001b[2;13Hwill\u001b[2;18Hexpire\u001b[2;25Hin\u001b[2;28H60\u001b[2;31Hminutes.\u001b[2;40HUpgrade\u001b[2;48Hto\u001b[2;51HPinggy\u001b[2;58HPro\u001b[2;62Hto\u001b[2;65Hget\u001b[2;69Hunrestricted\u001b[3;23Htunnels.\u001b[3;32Hhttps://dashboard.pinggy.io\u001b[5;4Hhttp://rnyni-34-55-81-164.a.free.pinggy.link\u001b[6;4Hhttps://rnyni-34-55-81-164.a.free.pinggy.link\u001b[9;26H                              \u001b[10;26H \u001b[10;55H \u001b[11;26H \u001b[11;28H    \u001b[11;33H     \u001b[11;39H  \u001b[11;42H       \u001b[11;50H   \u001b[11;55H \u001b[12;26H \u001b[12;40H  \u001b[12;55H \u001b[13;26H \u001b[13;55H \u001b[14;26H \u001b[14;55H \u001b[15;26H \u001b[15;55H \u001b[16;26H                              \u001b[24;28HPress\u001b[24;34H`h`\u001b[24;38Hfor\u001b[24;42Hkeybindings\u001b[25;81H\u001b[25;81H\u001b[25;81H\nTotal VRAM 15095 MB, total RAM 32103 MB\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 Tesla T4 : cudaMallocAsync\nVAE dtype: torch.bfloat16\nUsing pytorch cross attention\n\u001b[94mtheUpsiders Logic Nodes: \u001b[92mLoaded\u001b[0m\n\nImport times for custom nodes:\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Logic\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/Derfuu_ComfyUI_ModdedNodes\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Frame-Interpolation\n   0.3 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n   0.3 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\nFETCH ComfyRegistry Data: 5/57\nFETCH ComfyRegistry Data: 10/57\nFETCH ComfyRegistry Data: 15/57\nFETCH ComfyRegistry Data: 20/57\nFETCH ComfyRegistry Data: 25/57\nFETCH ComfyRegistry Data: 30/57\nFETCH ComfyRegistry Data: 35/57\nFETCH ComfyRegistry Data: 40/57\nFETCH ComfyRegistry Data: 45/57\nFETCH ComfyRegistry Data: 50/57\nFETCH ComfyRegistry Data: 55/57\nFETCH ComfyRegistry Data [DONE]\nnightly_channel: \n\u001b[4;94mhttps://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/remote\u001b[0m\nFETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\ngot prompt\nmodel_type V_PREDICTION_EDM\nadm 768\nUsing pytorch attention in VAE\nWorking with z of shape (1, 4, 32, 32) = 4096 dimensions.\nUsing pytorch attention in VAE\nleft over keys: dict_keys(['conditioner.embedders.0.open_clip.model.ln_final.bias', 'conditioner.embedders.0.open_clip.model.ln_final.weight', 'conditioner.embedders.0.open_clip.model.logit_scale', 'conditioner.embedders.0.open_clip.model.positional_embedding', 'conditioner.embedders.0.open_clip.model.text_projection', 'conditioner.embedders.0.open_clip.model.token_embedding.weight', 'conditioner.embedders.3.encoder.decoder.conv_in.bias', 'conditioner.embedders.3.encoder.decoder.conv_in.weight', 'conditioner.embedders.3.encoder.decoder.conv_out.bias', 'conditioner.embedders.3.encoder.decoder.conv_out.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.k.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.k.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.norm.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.norm.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.proj_out.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.proj_out.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.q.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.q.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.v.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.v.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.norm_out.bias', 'conditioner.embedders.3.encoder.decoder.norm_out.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.nin_shortcut.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.nin_shortcut.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.nin_shortcut.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.nin_shortcut.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.upsample.conv.bias', 'conditioner.embedders.3.encoder.decoder.up.1.upsample.conv.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.upsample.conv.bias', 'conditioner.embedders.3.encoder.decoder.up.2.upsample.conv.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.upsample.conv.bias', 'conditioner.embedders.3.encoder.decoder.up.3.upsample.conv.weight', 'conditioner.embedders.3.encoder.encoder.conv_in.bias', 'conditioner.embedders.3.encoder.encoder.conv_in.weight', 'conditioner.embedders.3.encoder.encoder.conv_out.bias', 'conditioner.embedders.3.encoder.encoder.conv_out.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.0.downsample.conv.bias', 'conditioner.embedders.3.encoder.encoder.down.0.downsample.conv.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.nin_shortcut.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.nin_shortcut.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.1.downsample.conv.bias', 'conditioner.embedders.3.encoder.encoder.down.1.downsample.conv.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.nin_shortcut.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.nin_shortcut.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.2.downsample.conv.bias', 'conditioner.embedders.3.encoder.encoder.down.2.downsample.conv.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.k.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.k.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.norm.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.norm.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.proj_out.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.proj_out.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.q.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.q.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.v.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.v.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_2.conv1.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_2.conv1.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_2.conv2.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_2.conv2.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_2.norm1.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_2.norm1.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_2.norm2.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_2.norm2.weight', 'conditioner.embedders.3.encoder.encoder.norm_out.bias', 'conditioner.embedders.3.encoder.encoder.norm_out.weight', 'conditioner.embedders.3.encoder.post_quant_conv.bias', 'conditioner.embedders.3.encoder.post_quant_conv.weight', 'conditioner.embedders.3.encoder.quant_conv.bias', 'conditioner.embedders.3.encoder.quant_conv.weight'])\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nRequested to load AutoencodingEngine\nLoading 1 new model\nRequested to load SVD_img2vid\nLoading 1 new model\n100%|███████████████████████████████████████████| 31/31 [12:36<00:00, 24.39s/it]\nRequested to load AutoencodingEngine\nLoading 1 new model\nDownloading: \"https://github.com/styler00dollar/VSGAN-tensorrt-docker/releases/download/models/rife47.pth\" to /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Frame-Interpolation/ckpts/rife/rife47.pth\n\n100%|███████████████████████████████████████| 20.4M/20.4M [00:00<00:00, 146MB/s]\nComfy-VFI: Clearing cache... Done cache clearing\nComfy-VFI: Clearing cache... Done cache clearing\nComfy-VFI done! 50 frames generated at resolution: torch.Size([3, 736, 736])\nComfy-VFI: Final clearing cache... Done cache clearing\nPrompt executed in 891.89 seconds\nConnection to a.pinggy.io closed by remote host.\nConnection to a.pinggy.io closed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m p_app\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     41\u001b[0m p_url\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 42\u001b[0m \u001b[43mp_app\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m p_url\u001b[38;5;241m.\u001b[39mjoin()\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWNOHANG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":2},{"cell_type":"markdown","source":"***\n**Option 2: Starting the Web UI with ngrok**  \n* Make sure to put your ngrok token in the Ngrok_token variable. The token can be obtained from https://ngrok.com\n* If you have a static domain, put your ngrok domain in the Ngrok_domain variable.\n* Wait for the line that says \"To see the GUI go to: http://127.0.0.1:8188 \" \n* Visit your ngrok URL (either your static domain, or the ngrok url displayed in the output)","metadata":{}},{"cell_type":"code","source":"# - Option 2: Running with Ngrok - #\n\nNgrok_token = \"\" #@param {type:\"string\"}\n# Put your ngrok token here (obtainable from https://ngrok.com)\n\nNgrok_domain = \"\" # optional, leave empty if you don't have a domain\n\n# -------------------------------- #\n\n!pip install pyngrok\n\nfrom pyngrok import ngrok, conf\nimport fileinput\nimport sys\n\nif Ngrok_token!=\"\":\n  ngrok.kill()\n  srv=ngrok.connect(8188 , pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token),\n                    bind_tls=True, domain=Ngrok_domain).public_url\n  print(srv)\n  get_ipython().system(f\"python {working_folder}/ComfyUI/main.py\")\nelse:\n  print('An ngrok token is required. You can get one on https://ngrok.com and paste it into the ngrok_token field.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Install a LoRA\n\nCopy the model URL to the model_url field. Make sure the model can be accessed publicly, without being signed into a website.","metadata":{}},{"cell_type":"code","source":"# Install a LoRA in temporary storage\nmodel_url = 'https://huggingface.co/HarroweD/HarrlogosXL/resolve/main/Harrlogos_v2.0.safetensors?download=true'\nmodel_name = 'Harrlogos_v2.0.safetensors'\n\n# Other model examples\n#model_url = 'https://civitai.com/api/download/models/153734?type=Model&format=SafeTensor'\n#model_name = 'DarkFantasy.safetensors'\n\n#model_url = 'https://civitai.com/api/download/models/81907'\n#model_name = 'CyberpunkAI.safetensors'\n\n#model_url = 'https://civitai.com/api/download/models/217866?type=Model&format=SafeTensor'\n#model_name = 'Wowifier.safetensors'\n\n%cd $temp_loras\nget_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install a LoRA in permanent storage\nmodel_url = 'https://civitai.com/api/download/models/132727'\nmodel_name = 'Samaritan.safetensors'\n\n%cd $loras\nget_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Install a Model\nCopy the model URL to the model_url field. Make sure the model can be accessed publicly, without being signed into a website.","metadata":{}},{"cell_type":"code","source":"# Install a model in temporary storage\nmodel_url = 'https://civitai.com/api/download/models/251662'\nmodel_name = 'DreamShaperXL-Turbo.safetensors'\n\n%cd $temp_models\nget_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install a model in permanent storage\n# Please check there is enough space and, if needed, delete a previous model using the \"Delete a model\" block.\nmodel_url = 'https://civitai.com/api/download/models/198962?type=Model&format=SafeTensor&size=pruned&fp=fp16'\nmodel_name = 'DynaVision.safetensors'\n\n%cd $checkpoints\nget_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Download a model for a custom node","metadata":{}},{"cell_type":"code","source":"model_folder = f'{working_folder}/ComfyUI/custom_nodes/my_node/models'\nmodel_url = ''\nmodel_name = 'model.safetensors'\n\n%cd $model_folder\nget_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# List permanent models","metadata":{}},{"cell_type":"code","source":"# List permanent models\n!ls -la $checkpoints","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Check a model's size","metadata":{}},{"cell_type":"code","source":"# Check the size of a model\nmodel_to_check = '/kaggle/working/ComfyUI/models/checkpoints/svd-fp16.safetensors'\n!du -sh $model_to_check ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Find files larger than 100M","metadata":{}},{"cell_type":"code","source":"!find $working_folder -size +100M","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Delete a file","metadata":{}},{"cell_type":"code","source":"# Delete a file to free up space\nmodel_to_delete = '/kaggle/working/ComfyUI/models/checkpoints/model.safetensors'\n!rm $model_to_delete","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Move outputs to a .zip file","metadata":{}},{"cell_type":"code","source":"# Create a .zip file \nimport datetime\nimport shutil \nimport os.path\n!mkdir $working_folder/outputs\n\ntimestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nzipfile = shutil.make_archive(f'{working_folder}/outputs/output_{timestamp}', 'zip', f'{working_folder}/ComfyUI/output')\n\nif os.path.exists(f'{working_folder}/outputs/output_{timestamp}.zip'):\n   print(f'Created {zipfile}') \nelse: \n   print(\"ZIP file not created\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Delete output files. \n# To avoid losing work, please make sure the ZIP file contains your outputs before running this step.\n\n!rm $outputs/*.*","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# File Browser","metadata":{}},{"cell_type":"markdown","source":"### Install and configure FileBrowser\n","metadata":{}},{"cell_type":"code","source":"%cd /kaggle\n!wget https://github.com/filebrowser/filebrowser/releases/download/v2.27.0/linux-amd64-filebrowser.tar.gz\n!tar xvfz linux-amd64-filebrowser.tar.gz\n!chmod a+x /kaggle/filebrowser\n!rm /kaggle/config.json\n!/kaggle/filebrowser config init \n!/kaggle/filebrowser config set --auth.method=noauth > /dev/null\n!/kaggle/filebrowser config set --branding.theme=dark > /dev/null\n!/kaggle/filebrowser users add admin admin \n!/kaggle/filebrowser config export \"/kaggle/config.json\"\n#!cat /kaggle/config.json # show the config file","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Start FileBrowser\n\nIf the app greets you with a login screen, the username and password are both \"admin\", which was set in the configuration code block above.\nClick the link ending with pinggy.link to open the File Browser.","metadata":{}},{"cell_type":"code","source":"# Starting FileBrowser with Pinggy\n\n%cd /kaggle\n        \nfrom multiprocessing import Process\nimport sys\nimport time\n\n!touch log.txt\nopen('log.txt', 'w').close()\n\ndef run_app():\n    !/kaggle/filebrowser -c \"/kaggle/config.json\" & ssh -o StrictHostKeyChecking=no -p 80 -R0:localhost:8080 a.pinggy.io > log.txt > log.txt\n    \ndef print_url():\n    print(\"waiting for output\")\n    time.sleep(2)\n    sys.stdout.flush()\n    \n    found = False\n    with open('log.txt', 'r') as file:\n        end_word = '.pinggy.link'\n        for line in file:\n            start_index = line.find(\"http:\")\n            if start_index != -1:\n                end_index = line.find(end_word, start_index)\n                if end_index != -1:\n                    print(\"😁 😁 😁\")\n                    print(\"URL: \" + line[start_index:end_index + len(end_word)])\n                    print(\"😁 😁 😁\")\n                    found = True\n    if not found:\n        print_url()\n    else:\n        with open('log.txt', 'r') as file:\n            for line in file:\n                print(line)\n    \np_app = Process(target=run_app)\np_url = Process(target=print_url)\np_app.start()\np_url.start()\np_app.join()\np_url.join()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \n# Delete the working folder","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}